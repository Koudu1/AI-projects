{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a221f84",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42e5934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "236f8f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.ConvLayer1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding='same')\n",
    "        self.PoolLayer = torch.nn.AvgPool2d(kernel_size=2)\n",
    "        self.ConvLayer2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.ConvLayer3 = torch.nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n",
    "        self.Linear1 = torch.nn.Linear(in_features=120, out_features=84)\n",
    "        self.Linear2 = torch.nn.Linear(in_features=84, out_features=num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.tanh(self.ConvLayer1(x))\n",
    "        x = self.PoolLayer(x)\n",
    "        x = torch.nn.functional.tanh(self.ConvLayer2(x))\n",
    "        x = self.PoolLayer(x)\n",
    "        x = torch.nn.functional.tanh(self.ConvLayer3(x))\n",
    "        x = torch.nn.Flatten()(x)\n",
    "        x = self.Linear1(x)\n",
    "        x = torch.nn.functional.tanh(x)\n",
    "        outputs = self.Linear2(x)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "668bc93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainLoader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    trainLoss = []\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for (inputs, labels) in trainLoader:\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        trainLoss.append(loss.item())\n",
    "\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epochAccuracy = 100 * correct / total\n",
    "    epochLoss = sum(trainLoss)/len(trainLoss)\n",
    "\n",
    "    return epochAccuracy, epochLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03978404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(model, validLoader, criterion, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validLoader:\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss)\n",
    "\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    epoch_acc = 100 * correct / total\n",
    "    epoch_loss = sum(losses)/len(losses)\n",
    "\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01108b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(root='data', download=False, train=True)\n",
    "test_data = torchvision.datasets.MNIST(root='data', download=False, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4eb5a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "number_train_data = int(len(train_data)*0.9)\n",
    "number_valid_samples = len(train_data) - number_train_data\n",
    "\n",
    "train_data, valid_data = torch.utils.data.random_split(train_data,\n",
    "                                                       [number_train_data, number_valid_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d10852bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.dataset.data.float().mean() / 255\n",
    "std = train_data.dataset.data.float().std() / 255\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize(mean=[mean], std=[std])])\n",
    "\n",
    "train_data.dataset.transform = transform\n",
    "valid_data.dataset.transform = transform\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "trainLoader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True)\n",
    "\n",
    "validLoader = torch.utils.data.DataLoader(valid_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e2cab45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1307) tensor(0.3081)\n"
     ]
    }
   ],
   "source": [
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85abf1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 1, Accuracy: 58.70%, Loss: 1.5854, Accuracy: 80.45%, Loss: 0.8990\n",
      "End of epoch 2, Accuracy: 84.08%, Loss: 0.6834, Accuracy: 88.10%, Loss: 0.4997\n",
      "End of epoch 3, Accuracy: 88.89%, Loss: 0.4434, Accuracy: 90.83%, Loss: 0.3563\n",
      "End of epoch 4, Accuracy: 91.05%, Loss: 0.3390, Accuracy: 92.50%, Loss: 0.2821\n",
      "End of epoch 5, Accuracy: 92.37%, Loss: 0.2774, Accuracy: 93.72%, Loss: 0.2331\n",
      "End of epoch 6, Accuracy: 93.58%, Loss: 0.2318, Accuracy: 94.78%, Loss: 0.1963\n",
      "End of epoch 7, Accuracy: 94.53%, Loss: 0.1957, Accuracy: 95.27%, Loss: 0.1669\n",
      "End of epoch 8, Accuracy: 95.36%, Loss: 0.1664, Accuracy: 95.95%, Loss: 0.1434\n",
      "End of epoch 9, Accuracy: 95.98%, Loss: 0.1442, Accuracy: 96.45%, Loss: 0.1252\n",
      "End of epoch 10, Accuracy: 96.46%, Loss: 0.1268, Accuracy: 96.85%, Loss: 0.1107\n",
      "End of epoch 11, Accuracy: 96.82%, Loss: 0.1131, Accuracy: 96.98%, Loss: 0.1005\n",
      "End of epoch 12, Accuracy: 97.05%, Loss: 0.1025, Accuracy: 97.20%, Loss: 0.0915\n",
      "End of epoch 13, Accuracy: 97.33%, Loss: 0.0936, Accuracy: 97.30%, Loss: 0.0844\n",
      "End of epoch 14, Accuracy: 97.54%, Loss: 0.0864, Accuracy: 97.60%, Loss: 0.0786\n",
      "End of epoch 15, Accuracy: 97.69%, Loss: 0.0805, Accuracy: 97.68%, Loss: 0.0734\n",
      "End of epoch 16, Accuracy: 97.83%, Loss: 0.0750, Accuracy: 97.77%, Loss: 0.0690\n",
      "End of epoch 17, Accuracy: 98.00%, Loss: 0.0706, Accuracy: 98.00%, Loss: 0.0650\n",
      "End of epoch 18, Accuracy: 98.05%, Loss: 0.0665, Accuracy: 98.07%, Loss: 0.0623\n",
      "End of epoch 19, Accuracy: 98.18%, Loss: 0.0630, Accuracy: 98.13%, Loss: 0.0590\n",
      "End of epoch 20, Accuracy: 98.26%, Loss: 0.0598, Accuracy: 98.28%, Loss: 0.0560\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_classes = len(train_data.dataset.classes)\n",
    "\n",
    "leNetClassifier = LeNet(num_classes)\n",
    "leNetClassifier.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(leNetClassifier.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 20\n",
    "model_path = './model'\n",
    "\n",
    "trainLosses, trainAccuracies = [], []\n",
    "validLosses, validAccuracies = [], []\n",
    "best_loss_eval = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    trainAccuracy, trainLoss = train(leNetClassifier, trainLoader, criterion, optimizer, device)\n",
    "    trainAccuracies.append(trainAccuracy)\n",
    "    trainLosses.append(trainLoss)\n",
    "\n",
    "    validAccuracy, validLoss = evaluateModel(leNetClassifier, validLoader, criterion, device)\n",
    "    validAccuracies.append(validAccuracy)\n",
    "    validLosses.append(validLoss)\n",
    "\n",
    "    if validLoss < best_loss_eval:\n",
    "        torch.save(leNetClassifier.state_dict(), model_path+'/leNet.pt')\n",
    "    \n",
    "    print(f\"End of epoch {epoch+1}, Accuracy: {trainAccuracy:.2f}%, Loss: {trainLoss:.4f}, Accuracy: {validAccuracy:.2f}%, Loss: {validLoss:.4f}\")\n",
    "\n",
    "    leNetClassifier.load_state_dict(torch.load(model_path+'/leNet.pt'))\n",
    "    leNetClassifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "588d93fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.2 tensor(0.0560, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test_data.transform = transform\n",
    "testLoader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "testAccuracy, testLoss = evaluateModel(leNetClassifier, testLoader, criterion, device)\n",
    "print(testAccuracy, testLoss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIVN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
