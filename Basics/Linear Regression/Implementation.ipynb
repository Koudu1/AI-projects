{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9567c38",
   "metadata": {},
   "source": [
    "## Implementation of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40fbadc",
   "metadata": {},
   "source": [
    "Tổng quát: **Linear Regression (Hồi quy tuyến tính)** là một thuật toán **học có giám sát**, được áp dụng chủ yếu trong các bài toán về hồi quy (**Regresison**) bằng việc tạo ra một hàm số toán học tuyến tính giữa các tính chất (**feature**) của một record với giá trị cần dự đoán. Ví dụ: Dự đoán giá nhà như một hàm số tuyến tính của các đặc điểm của ngôi nhà (số phòng ngủ, khoảng cách với trung tâm, ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347e10e",
   "metadata": {},
   "source": [
    "Bài toán: Giả sử ta có tập hợp các ngôi nhà được đại diện bằng một ma trận **X** có kích thước **MxN** với **M** là số lượng ngôi nhà đã được khảo sát và N là số lượng feature và một vector **y** chứa mức giá của căn nhà tương ứng. Nhiệm vụ là hãy dự đoán giá nhà của một ngôi nhà với feature vecto **z** có kích thước **1xN** với một hàm toán tuyến tính có dạng\n",
    "\n",
    "$$\n",
    "    Price = w_1*z_1 + w_2*z_2 + ... + w_n*z_n + b \n",
    "$$\n",
    "\n",
    "--> Để giải bài toán này, ta có thể sử dụng toán học để có thể tính toán chính xác các giá trị w. Tuy nhiên, theo cách của **Machine Learning**, ta cần phát triển các thành phần sau của thuật toán: \n",
    "- **Hàm mất mát (Loss Function)** có mục tiêu xác định chính xác sai số giữa giá trị thực và giá trị dự đoán\n",
    "- **Cực tiểu hóa** hàm mất mát\n",
    "- Thực hiện **update** các giá trị trọng số cho quan sát dựa trên **thuật toán cực tiểu hóa hàm mất mát** *(Gradient Descent, Evolutionary Algorithms,...)*   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bc1310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries for implementation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6d6bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w : np.ndarray, X : np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Function: Calculate the predicted y on a linear function\n",
    "\n",
    "    Args:\n",
    "        w (np.ndarray) : Coefficients or weights attached to each feature\n",
    "        X (np.ndarray) : Vector/Matrix of independent features of a dataset\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray : The predicted value of records\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return np.matmul(X, w.T)\n",
    "    except:\n",
    "        print(\"The shape of your matrix and your weight vector are not compatible!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8bf09",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a061fd1",
   "metadata": {},
   "source": [
    "Mean Squared Error\n",
    "\n",
    "$$\n",
    "    MSE = \\frac {1}{n} * \\sum_{i=1}^n (y_i - \\hat y_i)^2\n",
    "$$\n",
    "Theo đó, ,mất mát sẽ là **bình phương sai số** giữa giá trị thực và giá trị dự đoán "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9e11ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanSquaredError(yTrue : np.ndarray, yPred : np.array) -> np.array :\n",
    "    numberOfSamples = yTrue.shape[0]\n",
    "    return np.sum((yPred - yTrue)**2) / numberOfSamples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e472d5",
   "metadata": {},
   "source": [
    "### Gradient Descent (Algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "985f6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightGradient(yTrue : np.ndarray, yPred : np.ndarray, X : np.ndarray) -> np.ndarray:\n",
    "    numberOfSamples = X.shape[0]\n",
    "    return 2*X.T.dot(yPred - yTrue)/numberOfSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2141db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateWeight(w : np.ndarray, weightGradients : np.ndarray, learningRate : np.float16) -> np.ndarray:\n",
    "    return w.T - learningRate*weightGradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7f2bbf",
   "metadata": {},
   "source": [
    "### Examine in the real context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "87ed486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9]\n",
      " [2. ]]\n",
      "[[0.64]\n",
      " [3.24]]\n",
      "1.94\n",
      "(3, 1)\n",
      "[[0.056]\n",
      " [0.186]\n",
      " [0.18 ]]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[0.1, 0.2, 0.3]])\n",
    "X = np.array([[1, -5, 6], [2, 3, 4]])\n",
    "y = np.array([[0.1, 0.2]]).reshape(2,1)\n",
    "\n",
    "y_pred = predict(w, X)\n",
    "print(y_pred)\n",
    "print((y_pred - y)**2)\n",
    "print(meanSquaredError(y, y_pred))\n",
    "print(weightGradient(y, y_pred, X).shape)\n",
    "print(updateWeight(w, weightGradient(y, y_pred, X), learningRate = 0.01))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIVN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
